{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7939dee8-8cf1-43b2-bbf5-a32ac171a710",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m(syntax)\n\u001b[0;32m---> 46\u001b[0m nested_dictionary_cube \u001b[38;5;241m=\u001b[39m \u001b[43md2\u001b[49m\n\u001b[1;32m     47\u001b[0m nested_dictionary_measure_dimension \u001b[38;5;241m=\u001b[39m d1\n\u001b[1;32m     49\u001b[0m get_all_values(nested_dictionary_measure_dimension,nested_dictionary_cube)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd2' is not defined"
     ]
    }
   ],
   "source": [
    "import lkml as looker\n",
    "from pprint import pprint\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "from contextlib import redirect_stdout\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import yaml\n",
    "import git\n",
    "\n",
    "\n",
    "def get_all_values(nested_dictionary_measure_dimension,nested_dictionary_cube):\n",
    "\n",
    "    for key,value in nested_dictionary_cube.items():\n",
    "\n",
    "        cube = {\n",
    "\n",
    "            \"cube\": [key],\n",
    "\n",
    "            \"explore\": key+\"_explore\"+\" {\",\n",
    "\n",
    "            \"hidden\": \"no\",\n",
    "\n",
    "            \"view_name\": key\n",
    "                \n",
    "        }\n",
    "            \n",
    "        yield(looker.dump(cube))\n",
    "\n",
    "        for key,value in nested_dictionary_measure_dimension.items():\n",
    "\n",
    "            syntax = \"}\"\n",
    "\n",
    "\n",
    "        yield(syntax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nested_dictionary_cube = d2\n",
    "nested_dictionary_measure_dimension = d1\n",
    "\n",
    "get_all_values(nested_dictionary_measure_dimension,nested_dictionary_cube)\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        return (git_root)\n",
    "\n",
    "git_def_path = get_git_root(os.getcwd())\n",
    "\n",
    "\n",
    "def explore_output():\n",
    "    \n",
    "    git_path = git_def_path\n",
    "\n",
    "    rel_path = \"base\"\n",
    "\n",
    "    path = os.path.join(git_path, rel_path)\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    filename = 'cube.sql'\n",
    "\n",
    "    with open(os.path.join(path, filename), 'w') as file:\n",
    "\n",
    "        with redirect_stdout(file):\n",
    "\n",
    "                for value in get_all_values(nested_dictionary):\n",
    "\n",
    "                    print(value)\n",
    "\n",
    "explore_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53913525-bbae-43d8-9a87-b8d63858decc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mchained_assignment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mservice_account\n\u001b[1;32m     22\u001b[0m warehouse_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mwarehouse_name\n\u001b[1;32m     23\u001b[0m lookml_project \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mproject_name\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import lkml as looker\n",
    "from pprint import pprint\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "from contextlib import redirect_stdout\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import git\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "credentials = config.service_account\n",
    "\n",
    "warehouse_name = config.warehouse_name\n",
    "lookml_project = config.project_name\n",
    "\n",
    "sql = warehouse_target.warehouse_schema\n",
    "explore_sql = warehouse_target.explore_sql\n",
    "\n",
    "if warehouse_name == 'big_query':\n",
    "\n",
    "    # Run a Standard SQL query with the project set explicitly\n",
    "    project_id = lookml_project\n",
    "    df = pandas.read_gbq(sql, dialect='standard', project_id=lookml_project, credentials=credentials)\n",
    "\n",
    "    df['description'] = df['description'].fillna('not available')\n",
    "\n",
    "    df1 = df[['table_name','column_name','data_type','description']]\n",
    "\n",
    "    df1['data_type'] = df1['data_type'].str.replace('TIMESTAMP','timestamp')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('DATE','date')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('INT64','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('FLOAT64','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('NUMERIC','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('STRING','string')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('BOOL','yesno')\n",
    "\n",
    "    df2 = df1\n",
    "\n",
    "    explore_df = pandas.read_gbq(explore_sql, dialect='standard', project_id=lookml_project, credentials=credentials)\n",
    "\n",
    "    explore_df_2 = explore_df[['parent_table_name','pk_table_name', 'pk_column_name','fk_table_name','fk_column_name','looker_relationship']]\n",
    "\n",
    "    pk_table_name_df = explore_df[['pk_table_name']]\n",
    "\n",
    "    duplicate_explore_rows = pk_table_name_df[pk_table_name_df.duplicated(['pk_table_name'])]\n",
    "\n",
    "    distinct_duplicate_explore_rows = duplicate_explore_rows['pk_table_name'].drop_duplicates().to_list()\n",
    "\n",
    "elif warehouse_name == 'snowflake': \n",
    "\n",
    "    url = URL(\n",
    "\n",
    "        account = config.snowflake_account,\n",
    "        user =  config.snowflake_user,\n",
    "        schema =  config.snowflake_schema,\n",
    "        database =  config.snowflake_database,\n",
    "        password =  config.snowflake_password,\n",
    "        warehouse= config.snowflake_warehouse,\n",
    "        role =  config.snowflake_role\n",
    "\n",
    "    )\n",
    "\n",
    "    engine = create_engine(url)\n",
    "\n",
    "    connection = engine.connect()\n",
    "\n",
    "    query = '''\n",
    "    select * from snowflake_sample_data.information_schema.columns;\n",
    "    '''\n",
    "\n",
    "    df = pd.read_sql(query, connection)\n",
    "    \n",
    "    df['description'] = df['comment'].fillna('not available')\n",
    "    \n",
    "    df1 = df.groupby(['table_name', 'column_name','data_type','description']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    df2 = df1[['table_name','column_name','data_type','description']]\n",
    "\n",
    "    connection.close()\n",
    "    engine.dispose()\n",
    "\n",
    "    \n",
    "df3 = {n: grp.loc[n].to_dict('index')\n",
    "    \n",
    "for n, grp in df2.set_index(['table_name', 'column_name','data_type','description']).groupby(level='table_name')}\n",
    "\n",
    "d1 = df3\n",
    "\n",
    "##\n",
    "\n",
    "df4 = {n: grp.loc[n].to_dict('index')\n",
    "    \n",
    "for n, grp in explore_df.set_index(['parent_table_name','pk_table_name', 'pk_column_name','fk_table_name','fk_column_name','looker_relationship']).groupby(level='parent_table_name')}\n",
    "\n",
    "d2 = df4\n",
    "\n",
    "##\n",
    "\n",
    "def recur_dictify(frame):\n",
    "    if len(frame.columns) == 1:\n",
    "        if frame.values.size == 1: return frame.values[0][0]\n",
    "        return frame.values.squeeze()\n",
    "    grouped = frame.groupby(frame.columns[0])\n",
    "    d = {k: recur_dictify(g.iloc[:,1:]) for k,g in grouped}\n",
    "    return d\n",
    "\n",
    "\n",
    "\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f9df0f-0f27-4635-aaec-1c62fca7009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import yaml\n",
    "import git\n",
    "\n",
    "from jinjasql import JinjaSql\n",
    "from six import string_types\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "## source vars\n",
    "\n",
    "path = os.path.expanduser('~')\n",
    "\n",
    "profile_pass = os.path.join(path,\".droughty/profile.yaml\")\n",
    "\n",
    "with open(profile_pass) as f:\n",
    "    lookml_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        return (git_root)\n",
    "    \n",
    "    \n",
    "git_def_path = get_git_root(os.getcwd())\n",
    "\n",
    "git_path = git_def_path\n",
    "\n",
    "filename = 'droughty_project.yaml'\n",
    "\n",
    "droughty_project = os.path.join(git_path,filename)\n",
    "\n",
    "with open(droughty_project) as f:\n",
    "    enviroment_project = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "\n",
    "for key,value in enviroment_project.items():\n",
    "    \n",
    "    if key == 'profile':\n",
    "\n",
    "        if lookml_config[value]['warehouse_name'] == 'big_query':\n",
    "\n",
    "            if value in lookml_config:\n",
    "\n",
    "        ## global vars \n",
    "\n",
    "                warehouse_name =  lookml_config[value]['warehouse_name']\n",
    "                project_name =  lookml_config[value]['project_name']\n",
    "                schema_name =  lookml_config[value]['schema_name']\n",
    "                test_schemas = lookml_config[value]['test_schemas']\n",
    "                \n",
    "                warehouse_schema =   \"\"\"\n",
    "\n",
    "                with source as (\n",
    "\n",
    "                    select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "\n",
    "                    )\n",
    "\n",
    "                    select * from source\n",
    "\n",
    "                \"\"\".format(project_name,schema_name)\n",
    "\n",
    "                dbml_reference_dict = \"\"\"\n",
    "\n",
    "\n",
    "                with source as (\n",
    "\n",
    "                select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "\n",
    "                ),\n",
    "\n",
    "                    pks as (\n",
    "                    select \n",
    "                    table_name as pk_table_name,\n",
    "                    column_name as pk_column_name,\n",
    "                    trim(column_name, \"_pk\") as pk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%pk%'\n",
    "                    ),\n",
    "\n",
    "                    fks as (\n",
    "                    select\n",
    "                    table_name as fk_table_name,\n",
    "                    column_name as fk_column_name,\n",
    "                    trim(column_name, \"_fk\") as fk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%fk%'\n",
    "\n",
    "                    ),\n",
    "\n",
    "                    references as (\n",
    "                    select * from pks\n",
    "\n",
    "                    inner join fks on pks.pk_sk = fks.fk_sk\n",
    "\n",
    "                    )\n",
    "\n",
    "                    select \n",
    "                    \n",
    "                    *except (pk_column_name,pk_table_name),\n",
    "\n",
    "                    case when pk_column_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_column_name\n",
    "                    end as pk_column_name,\n",
    "\n",
    "                    case when pk_table_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_table_name\n",
    "                    end as pk_table_name                   \n",
    "                    from source\n",
    "\n",
    "                    left join references on source.column_name = references.fk_column_name and references.fk_table_name = source.table_name\n",
    "                \n",
    "                \"\"\".format(project_name,schema_name)\n",
    "\n",
    "        elif lookml_config[value]['warehouse_name'] == 'snowflake':\n",
    "            \n",
    "            if value in lookml_config:\n",
    "\n",
    "                warehouse_name =  lookml_config[value]['warehouse_name']\n",
    "                project_name =  lookml_config[value]['project_name']\n",
    "                schema_name =  lookml_config[value]['schema_name']\n",
    "                test_schemas = lookml_config[value]['test_schemas']\n",
    "                database = lookml_config[value]['database']\n",
    "\n",
    "                snowflake_schema = '''\n",
    "\n",
    "                select * from {0}.information_schema.columns;\n",
    "\n",
    "                '''.format(database)\n",
    "\n",
    "    ## warehouse test schemas\n",
    "\n",
    "test_warehouse_schema =   \"\"\"\n",
    "\n",
    "        with source_1 as (\n",
    "\n",
    "            select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMNS`\n",
    "\n",
    "            ),\n",
    "\n",
    "        source_2 as (\n",
    "\n",
    "        select * from `{0}.{2}.INFORMATION_SCHEMA.COLUMNS`\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        source_3 as (\n",
    "\n",
    "        select * from `{0}.{3}.INFORMATION_SCHEMA.COLUMNS`\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        unioned as (\n",
    "\n",
    "        select * from source_1\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_2\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_3\n",
    "        \n",
    "        )\n",
    "\n",
    "        select * from unioned\n",
    "\n",
    "\"\"\".format(project_name,test_schemas[0],test_schemas[1],test_schemas[2])\n",
    "\n",
    "explores = (enviroment_project.get(\"explores\"))\n",
    "\n",
    "## \n",
    "\n",
    "explore_tables = []\n",
    "\n",
    "for key,value in explores.items():\n",
    "\n",
    "    for key,value in value.items():\n",
    "\n",
    "        explore_tables.append(value)\n",
    "\n",
    "## reduce explore_tables from array to single list\n",
    "        \n",
    "single_list_tables = [i[0] for i in explore_tables]\n",
    "\n",
    "\n",
    "flat_list = []\n",
    "for sublist in explore_tables:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "final_list = []\n",
    "for x in flat_list:\n",
    "    final_list.append(\"'\" + x + \"'\")\n",
    "    \n",
    "join_key_list = ['merge_counts_fk','merge_counts_pk']\n",
    "\n",
    "params = {\n",
    "    'project_id': project_name,\n",
    "    'schema_id': schema_name, \n",
    "    'table_names': final_list,\n",
    "    'table_names_unqouted': flat_list,\n",
    "    'pk_fk_join_key_list': join_key_list\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "lookml_explore_schema = '''\n",
    "\n",
    "with source as (\n",
    "\n",
    "select \n",
    "\n",
    "*\n",
    "\n",
    "\n",
    "from `{{project_id}}.{{schema_id}}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "where table_name in \n",
    "{{ table_names |inclause }}\n",
    "\n",
    "),\n",
    "\n",
    "{% for value in table_names_unqouted  %}\n",
    "\n",
    "explore_table_row_count_{{ value | sqlsafe }} as (\n",
    "\n",
    "select \n",
    "\n",
    "'{{ value | sqlsafe }}' as table_name,\n",
    "count(*) as row_count\n",
    "\n",
    "from `{{project_id}}.{{schema_id}}.{{ value | sqlsafe }}`\n",
    "\n",
    "group by 1\n",
    "\n",
    "),\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "\n",
    "merge_counts as (\n",
    "\n",
    "\n",
    "{% for value in table_names_unqouted  %}\n",
    "\n",
    "select * from explore_table_row_count_{{ value | sqlsafe }}\n",
    "\n",
    "{% if not loop.last %}union all{% endif %}\n",
    "\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "\n",
    "),\n",
    "\n",
    "pks as (\n",
    "    select \n",
    "    table_name as pk_table_name,\n",
    "    column_name as pk_column_name,\n",
    "    trim(column_name, \"_pk\") as pk_sk,\n",
    "    from source\n",
    "    where column_name like '%%pk%%'\n",
    "),\n",
    "\n",
    "fks as (\n",
    "    select\n",
    "    table_name as fk_table_name,\n",
    "    column_name as fk_column_name,\n",
    "    trim(column_name, \"_fk\") as fk_sk,\n",
    "    from source\n",
    "    where column_name like '%%fk%%'\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "select \n",
    "\n",
    "{{ table_names [0] }} as parent_table_name,\n",
    "pk_table_name,\n",
    "pk_column_name,\n",
    "fk_table_name,\n",
    "fk_column_name,\n",
    "merge_counts_pk.row_count as pk_row_count,\n",
    "merge_counts_fk.row_count as fk_row_count,\n",
    "merge_counts_parent.row_count as parent_row_count,\n",
    "\n",
    "case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "        then 'many_to_one'   \n",
    "     when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "        then 'one_to_many'\n",
    "     when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "        then 'one_to_one'\n",
    "end as true_relationship,\n",
    "\n",
    "case when merge_counts_pk.row_count < merge_counts_parent.row_count\n",
    "    and merge_counts_fk.row_count < merge_counts_parent.row_count\n",
    "     or  merge_counts_pk.row_count != merge_counts_parent.row_count\n",
    "     and  merge_counts_fk.row_count != merge_counts_parent.row_count\n",
    "\n",
    "        then 'many_to_one'\n",
    "     when merge_counts_pk.row_count > merge_counts_parent.row_count\n",
    "        then 'one_to_many'\n",
    "     when merge_counts_fk.row_count > merge_counts_parent.row_count\n",
    "        then 'one_to_many'\n",
    "     when merge_counts_pk.row_count = merge_counts_parent.row_count\n",
    "     or merge_counts_fk.row_count = merge_counts_parent.row_count\n",
    "        then 'one_to_one'                \n",
    "        \n",
    "end as looker_relationship,\n",
    "\n",
    "     \n",
    "    \n",
    " \n",
    " \n",
    "from pks\n",
    "\n",
    "inner join fks on pks.pk_sk = fks.fk_sk\n",
    "\n",
    "left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "\n",
    "left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "\n",
    "left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\n",
    "\n",
    "\n",
    "order by looker_relationship\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "j = JinjaSql(param_style='pyformat')\n",
    "query, bind_params = j.prepare_query(lookml_explore_schema,params)\n",
    "\n",
    "isinstance(value, string_types)\n",
    "\n",
    "def quote_sql_string(value):\n",
    "    '''\n",
    "    If `value` is a string type, escapes single quotes in the string\n",
    "    and returns the string enclosed in single quotes.\n",
    "    '''\n",
    "    if isinstance(value, string_types):\n",
    "        new_value = str(value)\n",
    "        new_value = new_value.replace(\"'\", \"''\")\n",
    "        return \"'{}'\".format(new_value)\n",
    "    return value\n",
    "\n",
    "def get_sql_from_template(query, bind_params):\n",
    "    if not bind_params:\n",
    "        return query\n",
    "    params = deepcopy(bind_params)\n",
    "    for key, val in params.items():\n",
    "        params[key] = quote_sql_string(val)\n",
    "    return query % params\n",
    "\n",
    "def apply_sql_template(template, parameters):\n",
    "    '''\n",
    "    Apply a JinjaSql template (string) substituting parameters (dict) and return\n",
    "    the final SQL.\n",
    "    '''\n",
    "    j = JinjaSql(param_style='pyformat')\n",
    "    query, bind_params = j.prepare_query(template, parameters)\n",
    "    return get_sql_from_template(query, bind_params)\n",
    "\n",
    "explore_sql = (query % bind_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09a2c-c6ee-48dc-a171-5cee45d21f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
