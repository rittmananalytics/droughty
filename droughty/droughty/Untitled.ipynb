{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explores:\n",
    "\n",
    "    explore_tables: str\n",
    "    join_key_list: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb64fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_explore_list():\n",
    "\n",
    "    explores = [\"1\",\"2\",\"3\"]\n",
    "\n",
    "    Explores.explore_tables = explores\n",
    "    \n",
    "build_explore_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db514aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Explores.explore_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import yaml\n",
    "import git\n",
    "\n",
    "from jinjasql import JinjaSql\n",
    "from six import string_types\n",
    "from copy import deepcopy\n",
    "\n",
    "from droughty.config import ProjectVariables,ExploresVariables\n",
    "\n",
    "def warehouse_schema():\n",
    "\n",
    "    # generic warehouse schema\n",
    "\n",
    "    if ProjectVariables.warehouse == 'big_query':\n",
    "        \n",
    "        warehouse_schema =   \"\"\"\n",
    "        with source as (\n",
    "            select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "            )\n",
    "            select * from source\n",
    "        \"\"\".format(ProjectVariables.project,ProjectVariables.schema)\n",
    "\n",
    "    elif ProjectVariables.warehouse == 'snowflake':\n",
    "\n",
    "        warehouse_schema =   \"\"\"\n",
    "        with source as (\n",
    "            select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "            )\n",
    "            select * from source\n",
    "\n",
    "            where table_schema = '{1}'\n",
    "        \"\"\".format(ProjectVariables.database,ProjectVariables.schema)\n",
    "\n",
    "    return warehouse_schema\n",
    "\n",
    "def dbml_schema():\n",
    "\n",
    "    # dbml warehouse query\n",
    "\n",
    "    if ProjectVariables.warehouse == 'big_query':   \n",
    "\n",
    "        dbml_query = \"\"\"\n",
    "        with source as (\n",
    "        select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "        ),\n",
    "            pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            trim(column_name, \"_pk\") as pk_sk,\n",
    "            from source\n",
    "            where column_name like '%pk%'\n",
    "            ),\n",
    "            fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            trim(column_name, \"_fk\") as fk_sk,\n",
    "            from source\n",
    "            where column_name like '%fk%'\n",
    "            ),\n",
    "            references as (\n",
    "            select * from pks\n",
    "            inner join fks on pks.pk_sk = fks.fk_sk\n",
    "            )\n",
    "            select \n",
    "            \n",
    "            *except (pk_column_name,pk_table_name),\n",
    "            case when pk_column_name is null\n",
    "                then 'not_available'\n",
    "            else pk_column_name\n",
    "            end as pk_column_name,\n",
    "            case when pk_table_name is null\n",
    "                then 'not_available'\n",
    "            else pk_table_name\n",
    "            end as pk_table_name                   \n",
    "            from source\n",
    "            left join references on source.column_name = references.fk_column_name and references.fk_table_name = source.table_name\n",
    "        \n",
    "        \"\"\".format(ProjectVariables.project,ProjectVariables.schema)\n",
    "\n",
    "        return dbml_query\n",
    "\n",
    "    if ProjectVariables.warehouse == 'snowflake':   \n",
    "\n",
    "        dbml_query = \"\"\"\n",
    "        with source as (\n",
    "        select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "        where table_schema = '{1}'\n",
    "\n",
    "        ),\n",
    "            pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            rtrim(column_name, '_pk') as pk_sk\n",
    "            from source\n",
    "            where column_name like '%PK%'\n",
    "            ),\n",
    "            fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            rtrim(column_name, '_fk') as fk_sk\n",
    "            from source\n",
    "            where column_name like '%FK%'\n",
    "            ),\n",
    "            references as (\n",
    "            select * from pks\n",
    "            inner join fks on pks.pk_sk = fks.fk_sk\n",
    "            )\n",
    "            select \n",
    "            \n",
    "\n",
    "            source.data_type,\n",
    "            source.table_name,\n",
    "            source.column_name,\n",
    "            source.comment,\n",
    "\n",
    "            case when pk_column_name is null\n",
    "                then 'not_available'\n",
    "            else pk_column_name\n",
    "            end as pk_column_name,\n",
    "            case when pk_table_name is null\n",
    "                then 'not_available'\n",
    "            else pk_table_name\n",
    "            end as pk_table_name                   \n",
    "            from source\n",
    "            left join references on source.column_name = references.fk_column_name and references.fk_table_name = source.table_name\n",
    "        \n",
    "        \"\"\".format(ProjectVariables.database,ProjectVariables.schema)\n",
    "\n",
    "    # looker explore warehouse query\n",
    "\n",
    "def looker_explore_schema():\n",
    "\n",
    "    # looker explore warehouse query\n",
    "\n",
    "    if ProjectVariables.warehouse == 'big_query':   \n",
    "\n",
    "        lookml_explore_schema = '''\n",
    "        with source as (\n",
    "        select \n",
    "        *\n",
    "        from `{{project_id}}.{{schema_id}}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "        where table_name in \n",
    "        {{ table_names |inclause }}\n",
    "        ),\n",
    "        {% for value in table_names_unqouted  %}\n",
    "        explore_table_row_count_{{ value | sqlsafe }} as (\n",
    "        select \n",
    "        '{{ value | sqlsafe }}' as table_name,\n",
    "        count(*) as row_count\n",
    "        from `{{project_id}}.{{schema_id}}.{{ value | sqlsafe }}`\n",
    "        group by 1\n",
    "        ),\n",
    "        {% endfor %}\n",
    "        merge_counts as (\n",
    "        {% for value in table_names_unqouted  %}\n",
    "        select * from explore_table_row_count_{{ value | sqlsafe }}\n",
    "        {% if not loop.last %}union all{% endif %}\n",
    "        {% endfor %}\n",
    "        ),\n",
    "        pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            trim(column_name, \"_pk\") as pk_sk,\n",
    "            from source\n",
    "            where column_name like '%%pk%%'\n",
    "        ),\n",
    "        fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            trim(column_name, \"_fk\") as fk_sk,\n",
    "            from source\n",
    "            where column_name like '%%fk%%'\n",
    "        )\n",
    "        select \n",
    "        {{ table_names [0] }} as parent_table_name,\n",
    "        pk_table_name,\n",
    "        pk_column_name,\n",
    "        fk_table_name,\n",
    "        fk_column_name,\n",
    "        merge_counts_pk.row_count as pk_row_count,\n",
    "        merge_counts_fk.row_count as fk_row_count,\n",
    "        merge_counts_parent.row_count as parent_row_count,\n",
    "        case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                then 'many_to_one'   \n",
    "            when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                then 'one_to_one'\n",
    "        end as true_relationship,\n",
    "        case when merge_counts_pk.row_count < merge_counts_parent.row_count\n",
    "            and merge_counts_fk.row_count < merge_counts_parent.row_count\n",
    "            or  merge_counts_pk.row_count != merge_counts_parent.row_count\n",
    "            and  merge_counts_fk.row_count != merge_counts_parent.row_count\n",
    "                then 'many_to_one'\n",
    "            when merge_counts_pk.row_count > merge_counts_parent.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_fk.row_count > merge_counts_parent.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_pk.row_count = merge_counts_parent.row_count\n",
    "            or merge_counts_fk.row_count = merge_counts_parent.row_count\n",
    "                then 'one_to_one'                \n",
    "                \n",
    "        end as looker_relationship,\n",
    "        \n",
    "        from pks\n",
    "        inner join fks on pks.pk_sk = fks.fk_sk\n",
    "        left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "        left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "        left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\n",
    "        order by looker_relationship\n",
    "        '''\n",
    "\n",
    "    if ProjectVariables.warehouse == 'snowflake':   \n",
    "\n",
    "        lookml_explore_schema = '''\n",
    "        with source as (\n",
    "        select \n",
    "        *\n",
    "        from \"{{database}}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "        where table_name in \n",
    "        {{ table_names |inclause }}\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        {% for value in table_names_unqouted  %}\n",
    "        explore_table_row_count_{{ value | sqlsafe }} as (\n",
    "        select \n",
    "        '{{ value | sqlsafe }}' as table_name,\n",
    "        count(*) as row_count\n",
    "        from \"{{database}}\".\"{{schema_id}}\".\"{{ value | sqlsafe }}\"\n",
    "        group by 1\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        {% endfor %}\n",
    "        merge_counts as (\n",
    "        {% for value in table_names_unqouted  %}\n",
    "        select * from explore_table_row_count_{{ value | sqlsafe }}\n",
    "        {% if not loop.last %}union all{% endif %}\n",
    "        {% endfor %}\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            rtrim(column_name, '_PK') as pk_sk\n",
    "            from source\n",
    "            where column_name ilike '%%pk%%'\n",
    "        ),\n",
    "        fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            rtrim(column_name, '_FK') as fk_sk\n",
    "            from source\n",
    "            where column_name ilike '%%fk%%'\n",
    "        ),\n",
    "        \n",
    "        joined as (\n",
    "        select \n",
    "        {{ table_names [0] }} as parent_table_name,\n",
    "        pk_table_name,\n",
    "        pk_column_name,\n",
    "        fk_table_name,\n",
    "        fk_column_name,\n",
    "        merge_counts_pk.row_count as pk_row_count,\n",
    "        merge_counts_fk.row_count as fk_row_count,\n",
    "        merge_counts_parent.row_count as parent_row_count,\n",
    "        case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                then 'many_to_one'   \n",
    "            when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                then 'one_to_one'\n",
    "        end as true_relationship,\n",
    "        case when merge_counts_pk.row_count < merge_counts_parent.row_count\n",
    "            and merge_counts_fk.row_count < merge_counts_parent.row_count\n",
    "            or  merge_counts_pk.row_count != merge_counts_parent.row_count\n",
    "            and  merge_counts_fk.row_count != merge_counts_parent.row_count\n",
    "                then 'many_to_one'\n",
    "            when merge_counts_pk.row_count > merge_counts_parent.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_fk.row_count > merge_counts_parent.row_count\n",
    "                then 'one_to_many'\n",
    "            when merge_counts_pk.row_count = merge_counts_parent.row_count\n",
    "            or merge_counts_fk.row_count = merge_counts_parent.row_count\n",
    "                then 'one_to_one'                \n",
    "                \n",
    "        end as looker_relationship\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        from pks\n",
    "        join fks on pks.pk_sk = fks.fk_sk\n",
    "        left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "        left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "        left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\n",
    "        order by looker_relationship\n",
    "        \n",
    "        )\n",
    "        \n",
    "        select * from joined\n",
    "        \n",
    "        '''\n",
    "\n",
    "def dbt_test_schema():\n",
    "\n",
    "    if ProjectVariables.warehouse == 'big_query':   \n",
    "\n",
    "        test_warehouse_schema =   \"\"\"\n",
    "        with source_1 as (\n",
    "            select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMNS`\n",
    "            ),\n",
    "        source_2 as (\n",
    "        select * from `{0}.{2}.INFORMATION_SCHEMA.COLUMNS`\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        source_3 as (\n",
    "        select * from `{0}.{3}.INFORMATION_SCHEMA.COLUMNS`\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        unioned as (\n",
    "        select * from source_1\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_2\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_3\n",
    "        \n",
    "        )\n",
    "        select * from unioned\n",
    "        \"\"\".format(ProjectVariables.project,ProjectVariables.test_schemas[0],ProjectVariables.test_schemas[1],ProjectVariables.test_schemas[2])\n",
    "\n",
    "    if ProjectVariables.warehouse == 'snowflake':   \n",
    "\n",
    "        test_warehouse_schema =   \"\"\"\n",
    "        with source_1 as (\n",
    "            select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "\n",
    "            where table_schema = '{1}'\n",
    "\n",
    "            ),\n",
    "\n",
    "        source_2 as (\n",
    "            select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "\n",
    "            where table_schema = '{2}'\n",
    "\n",
    "\n",
    "        ),\n",
    "        \n",
    "        source_3 as (\n",
    "        select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "\n",
    "            where table_schema = '{3}'\n",
    "        \n",
    "        ),\n",
    "        \n",
    "        unioned as (\n",
    "        select * from source_1\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_2\n",
    "        \n",
    "        union all\n",
    "        \n",
    "        select * from source_3\n",
    "        \n",
    "        )\n",
    "        select * from unioned\n",
    "        \"\"\".format(ProjectVariables.database,ProjectVariables.test_schemas[0],ProjectVariables.test_schemas[1],ProjectVariables.test_schemas[2])\n",
    "\n",
    "def cube_explore_schema():\n",
    "\n",
    "    if ProjectVariables.warehouse == 'big_query':   \n",
    "\n",
    "        cube_explore_schema = '''\n",
    "        with source as (\n",
    "        select \n",
    "        *\n",
    "        from `{{project_id}}.{{schema_id}}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "        ),\n",
    "        row_counts as (\n",
    "        select\n",
    "            table_id as table_name,\n",
    "            row_count\n",
    "        from `{{project_id}}.{{schema_id}}.__TABLES__`\n",
    "        ),\n",
    "        pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            trim(column_name, \"_pk\") as pk_sk\n",
    "            from source\n",
    "            where column_name like '%%pk%%'\n",
    "        ),\n",
    "        fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            trim(column_name, \"_fk\") as fk_sk\n",
    "            from source\n",
    "            where column_name like '%%fk%%'\n",
    "        )\n",
    "        select \n",
    "        pk_table_name,\n",
    "        pk_column_name,\n",
    "        fk_table_name,\n",
    "        fk_column_name,\n",
    "        case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                then 'belongsTo'   \n",
    "            when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                then 'hasMany'\n",
    "            when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                then 'HasOne'\n",
    "        end as true_relationship\n",
    "        \n",
    "        from pks\n",
    "        inner join fks on pks.pk_sk = fks.fk_sk\n",
    "        left join row_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "        left join row_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "        '''\n",
    "\n",
    "    if ProjectVariables.warehouse == 'snowflake':   \n",
    "\n",
    "        cube_explore_schema = '''\n",
    "        with source as (\n",
    "        select \n",
    "        *\n",
    "        from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "        where table_schema = '{1}'\n",
    "        ),\n",
    "        row_counts as (\n",
    "        select\n",
    "            table_name,\n",
    "            sum(row_count) as row_count\n",
    "        from \"{0}\".\"INFORMATION_SCHEMA\".\"TABLES\"\n",
    "        where table_schema = '{1}'\n",
    "        group by 1\n",
    "        ),\n",
    "        pks as (\n",
    "            select \n",
    "            table_name as pk_table_name,\n",
    "            column_name as pk_column_name,\n",
    "            rtrim(column_name, '_PK') as pk_sk\n",
    "            from source\n",
    "            where column_name ilike '%pk%'\n",
    "        ),\n",
    "        fks as (\n",
    "            select\n",
    "            table_name as fk_table_name,\n",
    "            column_name as fk_column_name,\n",
    "            rtrim(column_name, '_FK') as fk_sk\n",
    "            from source\n",
    "            where column_name ilike '%fk%'\n",
    "        )\n",
    "        select \n",
    "        pk_table_name,\n",
    "        pk_column_name,\n",
    "        fk_table_name,\n",
    "        fk_column_name,\n",
    "        case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                then 'belongsTo'   \n",
    "            when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                then 'hasMany'\n",
    "            when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                then 'HasOne'\n",
    "        end as true_relationship\n",
    "        \n",
    "        from pks\n",
    "        left join fks on pks.pk_sk = fks.fk_sk\n",
    "        left join row_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "        left join row_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "        '''.format(ProjectVariables.database,ProjectVariables.schema)\n",
    "\n",
    "if ProjectVariables.warehouse == 'big_query':\n",
    "\n",
    "    params = {\n",
    "        'project_id': ProjectVariables.project,\n",
    "        'schema_id': ProjectVariables.schema, \n",
    "        'table_names': ExploresVariables.final_list,\n",
    "        'table_names_unqouted': ExploresVariables.flat_list,\n",
    "        'pk_fk_join_key_list': ExploresVariables.join_key_list\n",
    "\n",
    "    }\n",
    "\n",
    "elif ProjectVariables.warehouse == 'snowflake':\n",
    "\n",
    "    params = {\n",
    "        'database': ProjectVariables.database,\n",
    "        'schema_id': ProjectVariables.schema, \n",
    "        'table_names': ExploresVariables.final_list,\n",
    "        'table_names_unqouted': ExploresVariables.flat_list,\n",
    "        'pk_fk_join_key_list': ExploresVariables.join_key_list\n",
    "\n",
    "    }\n",
    "\n",
    "explore_sql = looker_explore_schema()\n",
    "cube_sql = cube_explore_schema()\n",
    "\n",
    "j = JinjaSql(param_style='pyformat')\n",
    "\n",
    "query, bind_params = j.prepare_query(explore_sql,params)\n",
    "\n",
    "cube_query, cube_bind_params = j.prepare_query(cube_sql,params)\n",
    "\n",
    "\n",
    "isinstance(value, string_types)\n",
    "\n",
    "def quote_sql_string(value):\n",
    "    '''\n",
    "    If `value` is a string type, escapes single quotes in the string\n",
    "    and returns the string enclosed in single quotes.\n",
    "    '''\n",
    "    if isinstance(value, string_types):\n",
    "        new_value = str(value)\n",
    "        new_value = new_value.replace(\"'\", \"''\")\n",
    "        return \"'{}'\".format(new_value)\n",
    "    return value\n",
    "\n",
    "def get_sql_from_template(query, bind_params):\n",
    "    if not bind_params:\n",
    "        return query\n",
    "    params = deepcopy(bind_params)\n",
    "    for key, val in params.items():\n",
    "        params[key] = quote_sql_string(val)\n",
    "    return query % params\n",
    "\n",
    "def apply_sql_template(template, parameters):\n",
    "    '''\n",
    "    Apply a JinjaSql template (string) substituting parameters (dict) and return\n",
    "    the final SQL.\n",
    "    '''\n",
    "    j = JinjaSql(param_style='pyformat')\n",
    "    query, bind_params = j.prepare_query(template, parameters)\n",
    "    return get_sql_from_template(query, bind_params)\n",
    "\n",
    "explore_sql = (query % bind_params)\n",
    "\n",
    "if ProjectVariables.warehouse =='big_query':\n",
    "\n",
    "    cube_explore_schema = (query % bind_params)\n",
    "\n",
    "elif ProjectVariables.warehouse == 'snowflake':\n",
    "    \n",
    "    cube_explore_schema = cube_explore_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa77b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--profile-dir PROFILE_DIR]\n",
      "                             {lookml,cube,dbml,dbt} ...\n",
      "ipykernel_launcher.py: error: argument command: invalid choice: '/Users/lewischarlesbaker/Library/Jupyter/runtime/kernel-3c476ca8-55db-465c-a5bc-aa826a881f65.json' (choose from 'lookml', 'cube', 'dbml', 'dbt')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:1800\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1800\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(namespace, _UNRECOGNIZED_ARGS_ATTR):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:2009\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n\u001b[0;32m-> 2009\u001b[0m stop_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_positionals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[38;5;66;03m# if we didn't consume all the argument strings, there were extras\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:1965\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     start_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m arg_count\n\u001b[0;32m-> 1965\u001b[0m     \u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;66;03m# slice off the Positionals that we just parsed and return the\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;66;03m# index at which the Positionals' string args stopped\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:1858\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1857\u001b[0m seen_actions\u001b[38;5;241m.\u001b[39madd(action)\n\u001b[0;32m-> 1858\u001b[0m argument_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_strings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;66;03m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:2399\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2398\u001b[0m     value \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(action, v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m arg_strings]\n\u001b[0;32m-> 2399\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;66;03m# SUPPRESS argument does not put anything in the namespace\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:2446\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2445\u001b[0m msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid choice: \u001b[39m\u001b[38;5;132;01m%(value)r\u001b[39;00m\u001b[38;5;124m (choose from \u001b[39m\u001b[38;5;132;01m%(choices)s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2446\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m args)\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument command: invalid choice: '/Users/lewischarlesbaker/Library/Jupyter/runtime/kernel-3c476ca8-55db-465c-a5bc-aa826a881f65.json' (choose from 'lookml', 'cube', 'dbml', 'dbt')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProjectVariables\n",
      "File \u001b[0;32m~/Documents/GitHub/droughty/droughty/droughty/config.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moauth2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service_account\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdroughty\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_cli\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Common\n\u001b[1;32m     10\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/droughty/config_cli.py:59\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     Common\u001b[38;5;241m.\u001b[39mprofile_dir \u001b[38;5;241m=\u001b[39m (args\u001b[38;5;241m.\u001b[39mprofile_dir)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mprofile_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/droughty/config_cli.py:48\u001b[0m, in \u001b[0;36mprofile_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# parsing arguments\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#some_function_1(args.profile_dir)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# assigning arguments to class\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:1768\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1768\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:1807\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1806\u001b[0m err \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:2521\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2520\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/argparse.py:2508\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2508\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1927\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   1925\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1926\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1927\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1930\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1931\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   1932\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:578\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:436\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    433\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    434\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    435\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 436\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:1105\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:999\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    996\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:852\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m etb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    856\u001b[0m colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:786\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    785\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m--> 786\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    789\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/IPython/core/ultratb.py:840\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    834\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[1;32m    835\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[1;32m    836\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[1;32m    837\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    838\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m etb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/stack_data/core.py:534\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    525\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/.virtualenvs/droughty_dev_0.1.0/lib/python3.8/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import yaml\n",
    "import git\n",
    "\n",
    "from jinjasql import JinjaSql\n",
    "from six import string_types\n",
    "from copy import deepcopy\n",
    "\n",
    "from config import ProjectVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562e5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
