{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3454a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import yaml\n",
    "import git\n",
    "\n",
    "from jinjasql import JinjaSql\n",
    "from six import string_types\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "## source vars\n",
    "\n",
    "path = os.path.expanduser('~')\n",
    "\n",
    "profile_pass = os.path.join(path,\".droughty/profile.yaml\")\n",
    "\n",
    "with open(profile_pass) as f:\n",
    "    lookml_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "def get_git_root(path):\n",
    "\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        return (git_root)\n",
    "    \n",
    "    \n",
    "git_def_path = get_git_root(os.getcwd())\n",
    "\n",
    "git_path = git_def_path\n",
    "\n",
    "filename = 'droughty_project.yaml'\n",
    "\n",
    "droughty_project = os.path.join(git_path,filename)\n",
    "\n",
    "with open(droughty_project) as f:\n",
    "    enviroment_project = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "\n",
    "for key,value in enviroment_project.items():\n",
    "    \n",
    "    if key == 'profile':\n",
    "\n",
    "        if lookml_config[value]['warehouse_name'] == 'big_query':\n",
    "\n",
    "            if value in lookml_config:\n",
    "\n",
    "        ## global vars \n",
    "\n",
    "                warehouse_name =  lookml_config[value]['warehouse_name']\n",
    "                project_name =  lookml_config[value]['project_name']\n",
    "                schema_name =  lookml_config[value]['schema_name']\n",
    "                test_schemas = lookml_config[value]['test_schemas']\n",
    "                \n",
    "                warehouse_schema =   \"\"\"\n",
    "                with source as (\n",
    "                    select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "                    )\n",
    "                    select * from source\n",
    "                \"\"\".format(project_name,schema_name)\n",
    "\n",
    "                dbml_reference_dict = \"\"\"\n",
    "                with source as (\n",
    "                select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "                ),\n",
    "                    pks as (\n",
    "                    select \n",
    "                    table_name as pk_table_name,\n",
    "                    column_name as pk_column_name,\n",
    "                    trim(column_name, \"_pk\") as pk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%pk%'\n",
    "                    ),\n",
    "                    fks as (\n",
    "                    select\n",
    "                    table_name as fk_table_name,\n",
    "                    column_name as fk_column_name,\n",
    "                    trim(column_name, \"_fk\") as fk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%fk%'\n",
    "                    ),\n",
    "                    references as (\n",
    "                    select * from pks\n",
    "                    inner join fks on pks.pk_sk = fks.fk_sk\n",
    "                    )\n",
    "                    select \n",
    "                    \n",
    "                    *except (pk_column_name,pk_table_name),\n",
    "                    case when pk_column_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_column_name\n",
    "                    end as pk_column_name,\n",
    "                    case when pk_table_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_table_name\n",
    "                    end as pk_table_name                   \n",
    "                    from source\n",
    "                    left join references on source.column_name = references.fk_column_name and references.fk_table_name = source.table_name\n",
    "                \n",
    "                \"\"\".format(project_name,schema_name)\n",
    "\n",
    "                lookml_explore_schema = '''\n",
    "                with source as (\n",
    "                select \n",
    "                *\n",
    "                from `{{project_id}}.{{schema_id}}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "                where table_name in \n",
    "                {{ table_names |inclause }}\n",
    "                ),\n",
    "                {% for value in table_names_unqouted  %}\n",
    "                explore_table_row_count_{{ value | sqlsafe }} as (\n",
    "                select \n",
    "                '{{ value | sqlsafe }}' as table_name,\n",
    "                count(*) as row_count\n",
    "                from `{{project_id}}.{{schema_id}}.{{ value | sqlsafe }}`\n",
    "                group by 1\n",
    "                ),\n",
    "                {% endfor %}\n",
    "                merge_counts as (\n",
    "                {% for value in table_names_unqouted  %}\n",
    "                select * from explore_table_row_count_{{ value | sqlsafe }}\n",
    "                {% if not loop.last %}union all{% endif %}\n",
    "                {% endfor %}\n",
    "                ),\n",
    "                pks as (\n",
    "                    select \n",
    "                    table_name as pk_table_name,\n",
    "                    column_name as pk_column_name,\n",
    "                    trim(column_name, \"_pk\") as pk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%%pk%%'\n",
    "                ),\n",
    "                fks as (\n",
    "                    select\n",
    "                    table_name as fk_table_name,\n",
    "                    column_name as fk_column_name,\n",
    "                    trim(column_name, \"_fk\") as fk_sk,\n",
    "                    from source\n",
    "                    where column_name like '%%fk%%'\n",
    "                )\n",
    "                select \n",
    "                {{ table_names [0] }} as parent_table_name,\n",
    "                pk_table_name,\n",
    "                pk_column_name,\n",
    "                fk_table_name,\n",
    "                fk_column_name,\n",
    "                merge_counts_pk.row_count as pk_row_count,\n",
    "                merge_counts_fk.row_count as fk_row_count,\n",
    "                merge_counts_parent.row_count as parent_row_count,\n",
    "                case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                        then 'many_to_one'   \n",
    "                    when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                        then 'one_to_one'\n",
    "                end as true_relationship,\n",
    "                case when merge_counts_pk.row_count < merge_counts_parent.row_count\n",
    "                    and merge_counts_fk.row_count < merge_counts_parent.row_count\n",
    "                    or  merge_counts_pk.row_count != merge_counts_parent.row_count\n",
    "                    and  merge_counts_fk.row_count != merge_counts_parent.row_count\n",
    "                        then 'many_to_one'\n",
    "                    when merge_counts_pk.row_count > merge_counts_parent.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_fk.row_count > merge_counts_parent.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_pk.row_count = merge_counts_parent.row_count\n",
    "                    or merge_counts_fk.row_count = merge_counts_parent.row_count\n",
    "                        then 'one_to_one'                \n",
    "                        \n",
    "                end as looker_relationship,\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                from pks\n",
    "                inner join fks on pks.pk_sk = fks.fk_sk\n",
    "                left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "                left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "                left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\n",
    "                order by looker_relationship\n",
    "                '''\n",
    "\n",
    "                test_warehouse_schema =   \"\"\"\n",
    "                with source_1 as (\n",
    "                    select * from `{0}.{1}.INFORMATION_SCHEMA.COLUMNS`\n",
    "                    ),\n",
    "                source_2 as (\n",
    "                select * from `{0}.{2}.INFORMATION_SCHEMA.COLUMNS`\n",
    "                \n",
    "                ),\n",
    "                \n",
    "                source_3 as (\n",
    "                select * from `{0}.{3}.INFORMATION_SCHEMA.COLUMNS`\n",
    "                \n",
    "                ),\n",
    "                \n",
    "                unioned as (\n",
    "                select * from source_1\n",
    "                \n",
    "                union all\n",
    "                \n",
    "                select * from source_2\n",
    "                \n",
    "                union all\n",
    "                \n",
    "                select * from source_3\n",
    "                \n",
    "                )\n",
    "                select * from unioned\n",
    "                \"\"\".format(project_name,test_schemas[0],test_schemas[1],test_schemas[2])\n",
    "\n",
    "        elif lookml_config[value]['warehouse_name'] == 'snowflake':\n",
    "            \n",
    "            if value in lookml_config:\n",
    "\n",
    "                warehouse_name =  lookml_config[value]['warehouse_name']\n",
    "                project_name =  lookml_config[value]['project_name']\n",
    "                schema_name =  lookml_config[value]['schema_name']\n",
    "                test_schemas = lookml_config[value]['test_schemas']\n",
    "                database = lookml_config[value]['database']\n",
    "\n",
    "                warehouse_schema =   \"\"\"\n",
    "                with source as (\n",
    "                    select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                    )\n",
    "                    select * from source\n",
    "                \"\"\".format(database)\n",
    "\n",
    "                dbml_reference_dict = \"\"\"\n",
    "                with source as (\n",
    "                select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                ),\n",
    "                    pks as (\n",
    "                    select \n",
    "                    table_name as pk_table_name,\n",
    "                    column_name as pk_column_name,\n",
    "                    trim(column_name, '_pk') as pk_sk\n",
    "                    from source\n",
    "                    where column_name like '%pk%'\n",
    "                    ),\n",
    "                    fks as (\n",
    "                    select\n",
    "                    table_name as fk_table_name,\n",
    "                    column_name as fk_column_name,\n",
    "                    trim(column_name, '_fk') as fk_sk\n",
    "                    from source\n",
    "                    where column_name like '%fk%'\n",
    "                    ),\n",
    "                    references as (\n",
    "                    select * from pks\n",
    "                    inner join fks on pks.pk_sk = fks.fk_sk\n",
    "                    )\n",
    "                    select \n",
    "                    \n",
    "                    *,\n",
    "                    case when pk_column_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_column_name\n",
    "                    end as pk_column_name,\n",
    "                    case when pk_table_name is null\n",
    "                        then 'not_available'\n",
    "                    else pk_table_name\n",
    "                    end as pk_table_name                   \n",
    "                    from source\n",
    "                    left join references on source.column_name = references.fk_column_name and references.fk_table_name = source.table_name\n",
    "                \n",
    "                \"\"\".format(database)\n",
    "\n",
    "                lookml_explore_schema = '''\n",
    "                with source as (\n",
    "                select \n",
    "                *\n",
    "                from \"{{database}}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                where table_name in \n",
    "                {{ table_names |inclause }}\n",
    "                ),\n",
    "                {% for value in table_names_unqouted  %}\n",
    "                explore_table_row_count_{{ value | sqlsafe }} as (\n",
    "                select \n",
    "                '{{ value | sqlsafe }}' as table_name,\n",
    "                count(*) as row_count\n",
    "                from \"{{database}}\".\"{{schema_id}}\".\"{{ value | sqlsafe }}\"\n",
    "                group by 1\n",
    "                ),\n",
    "                {% endfor %}\n",
    "                merge_counts as (\n",
    "                {% for value in table_names_unqouted  %}\n",
    "                select * from explore_table_row_count_{{ value | sqlsafe }}\n",
    "                {% if not loop.last %}union all{% endif %}\n",
    "                {% endfor %}\n",
    "                ),\n",
    "                pks as (\n",
    "                    select \n",
    "                    table_name as pk_table_name,\n",
    "                    column_name as pk_column_name,\n",
    "                    trim(column_name, '_pk') as pk_sk\n",
    "                    from source\n",
    "                    where column_name like '%%pk%%'\n",
    "                ),\n",
    "                fks as (\n",
    "                    select\n",
    "                    table_name as fk_table_name,\n",
    "                    column_name as fk_column_name,\n",
    "                    trim(column_name, '_fk') as fk_sk\n",
    "                    from source\n",
    "                    where column_name like '%%fk%%'\n",
    "                )\n",
    "                select \n",
    "                {{ table_names [0] }} as parent_table_name,\n",
    "                pk_table_name,\n",
    "                pk_column_name,\n",
    "                fk_table_name,\n",
    "                fk_column_name,\n",
    "                merge_counts_pk.row_count as pk_row_count,\n",
    "                merge_counts_fk.row_count as fk_row_count,\n",
    "                merge_counts_parent.row_count as parent_row_count,\n",
    "                case when merge_counts_pk.row_count > merge_counts_fk.row_count\n",
    "                        then 'many_to_one'   \n",
    "                    when merge_counts_pk.row_count < merge_counts_fk.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_pk.row_count = merge_counts_fk.row_count\n",
    "                        then 'one_to_one'\n",
    "                end as true_relationship,\n",
    "                case when merge_counts_pk.row_count < merge_counts_parent.row_count\n",
    "                    and merge_counts_fk.row_count < merge_counts_parent.row_count\n",
    "                    or  merge_counts_pk.row_count != merge_counts_parent.row_count\n",
    "                    and  merge_counts_fk.row_count != merge_counts_parent.row_count\n",
    "                        then 'many_to_one'\n",
    "                    when merge_counts_pk.row_count > merge_counts_parent.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_fk.row_count > merge_counts_parent.row_count\n",
    "                        then 'one_to_many'\n",
    "                    when merge_counts_pk.row_count = merge_counts_parent.row_count\n",
    "                    or merge_counts_fk.row_count = merge_counts_parent.row_count\n",
    "                        then 'one_to_one'                \n",
    "                        \n",
    "                end as looker_relationship\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                from pks\n",
    "                inner join fks on pks.pk_sk = fks.fk_sk\n",
    "                left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\n",
    "                left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\n",
    "                left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\n",
    "                order by looker_relationship\n",
    "                '''\n",
    "\n",
    "                test_warehouse_schema =   \"\"\"\n",
    "                with source_1 as (\n",
    "                    select * from \"{0}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                    ),\n",
    "                source_2 as (\n",
    "                select * from \"{1}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                \n",
    "                ),\n",
    "                \n",
    "                source_3 as (\n",
    "                select * from \"{2}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "                \n",
    "                ),\n",
    "                \n",
    "                unioned as (\n",
    "                select * from source_1\n",
    "                \n",
    "                union all\n",
    "                \n",
    "                select * from source_2\n",
    "                \n",
    "                union all\n",
    "                \n",
    "                select * from source_3\n",
    "                \n",
    "                )\n",
    "                select * from unioned\n",
    "                \"\"\".format(test_schemas[0],test_schemas[1],test_schemas[2])\n",
    "\n",
    "\n",
    "\n",
    "explores = (enviroment_project.get(\"explores\"))\n",
    "\n",
    "dimensional_inference = (enviroment_project.get(\"dimensional_inference\"))\n",
    "\n",
    "## \n",
    "\n",
    "explore_tables = []\n",
    "\n",
    "for key,value in explores.items():\n",
    "\n",
    "    for key,value in value.items():\n",
    "\n",
    "        explore_tables.append(value)\n",
    "\n",
    "## reduce explore_tables from array to single list\n",
    "        \n",
    "single_list_tables = [i[0] for i in explore_tables]\n",
    "\n",
    "\n",
    "flat_list = []\n",
    "for sublist in explore_tables:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "final_list = []\n",
    "for x in flat_list:\n",
    "    final_list.append(\"'\" + x + \"'\")\n",
    "    \n",
    "join_key_list = ['merge_counts_fk','merge_counts_pk']\n",
    "\n",
    "## add for snowflake\n",
    "\n",
    "for key,value in enviroment_project.items():\n",
    "\n",
    "    if key == 'profile':\n",
    "\n",
    "        if lookml_config[value]['warehouse_name'] == 'big_query':\n",
    "\n",
    "            params = {\n",
    "                'project_id': project_name,\n",
    "                'schema_id': schema_name, \n",
    "                'table_names': final_list,\n",
    "                'table_names_unqouted': flat_list,\n",
    "                'pk_fk_join_key_list': join_key_list\n",
    "\n",
    "            }\n",
    "\n",
    "        elif lookml_config[value]['warehouse_name'] == 'snowflake':\n",
    "\n",
    "            params = {\n",
    "                'database': database,\n",
    "                'schema_id': schema_name, \n",
    "                'table_names': final_list,\n",
    "                'table_names_unqouted': flat_list,\n",
    "                'pk_fk_join_key_list': join_key_list\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "j = JinjaSql(param_style='pyformat')\n",
    "query, bind_params = j.prepare_query(lookml_explore_schema,params)\n",
    "\n",
    "isinstance(value, string_types)\n",
    "\n",
    "def quote_sql_string(value):\n",
    "    '''\n",
    "    If `value` is a string type, escapes single quotes in the string\n",
    "    and returns the string enclosed in single quotes.\n",
    "    '''\n",
    "    if isinstance(value, string_types):\n",
    "        new_value = str(value)\n",
    "        new_value = new_value.replace(\"'\", \"''\")\n",
    "        return \"'{}'\".format(new_value)\n",
    "    return value\n",
    "\n",
    "def get_sql_from_template(query, bind_params):\n",
    "    if not bind_params:\n",
    "        return query\n",
    "    params = deepcopy(bind_params)\n",
    "    for key, val in params.items():\n",
    "        params[key] = quote_sql_string(val)\n",
    "    return query % params\n",
    "\n",
    "def apply_sql_template(template, parameters):\n",
    "    '''\n",
    "    Apply a JinjaSql template (string) substituting parameters (dict) and return\n",
    "    the final SQL.\n",
    "    '''\n",
    "    j = JinjaSql(param_style='pyformat')\n",
    "    query, bind_params = j.prepare_query(template, parameters)\n",
    "    return get_sql_from_template(query, bind_params)\n",
    "\n",
    "explore_sql = (query % bind_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702cba15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                with source_1 as (\\n                    select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                    ),\\n                source_2 as (\\n                select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                \\n                ),\\n                \\n                source_3 as (\\n                select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                \\n                ),\\n                \\n                unioned as (\\n                select * from source_1\\n                \\n                union all\\n                \\n                select * from source_2\\n                \\n                union all\\n                \\n                select * from source_3\\n                \\n                )\\n                select * from unioned\\n                '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_warehouse_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10974cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lkml as looker\n",
    "from pprint import pprint\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "from contextlib import redirect_stdout\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "import config\n",
    "\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "import git\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "sql = test_warehouse_schema\n",
    "\n",
    "credentials = config.service_account\n",
    "\n",
    "warehouse_name = config.warehouse_name\n",
    "lookml_project = config.project_name\n",
    "\n",
    "\n",
    "\n",
    "if warehouse_name == 'big_query':\n",
    "\n",
    "    # Run a Standard SQL query using the environment's default project\n",
    "    df = pandas.read_gbq(sql, dialect='standard', project_id=lookml_project, credentials=credentials)\n",
    "\n",
    "    # Run a Standard SQL query with the project set explicitly\n",
    "    project_id = lookml_project\n",
    "    df = pandas.read_gbq(sql, dialect='standard', project_id=lookml_project, credentials=credentials)\n",
    "\n",
    "    df1 = df[['table_name','column_name','data_type']]\n",
    "\n",
    "    df1['data_type'] = df1['data_type'].str.replace('TIMESTAMP','timestamp')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('DATE','date')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('INT64','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('FLOAT64','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('NUMERIC','number')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('STRING','string')\n",
    "    df1['data_type'] = df1['data_type'].str.replace('BOOL','yesno')\n",
    "\n",
    "elif warehouse_name == 'snowflake': \n",
    "\n",
    "    url = URL(\n",
    "\n",
    "        account = config.snowflake_account,\n",
    "        user =  config.snowflake_user,\n",
    "        schema =  config.snowflake_schema,\n",
    "        database =  config.snowflake_database,\n",
    "        password =  config.snowflake_password,\n",
    "        warehouse= config.snowflake_warehouse,\n",
    "        role =  config.snowflake_role\n",
    "\n",
    "    )\n",
    "\n",
    "    engine = create_engine(url)\n",
    "\n",
    "    connection = engine.connect()\n",
    "\n",
    "    query = sql\n",
    "\n",
    "    df = pd.read_sql(query, connection)\n",
    "    \n",
    "    df['description'] = df['comment'].fillna('not available')\n",
    "    \n",
    "    df1 = df.groupby(['table_name', 'column_name','data_type','description']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    df1 = df1[['table_name','column_name','data_type','description']]\n",
    "\n",
    "    connection.close()\n",
    "    engine.dispose()\n",
    "\n",
    "def recur_dictify(frame):\n",
    "    if len(frame.columns) == 1:\n",
    "        if frame.values.size == 1: return frame.values[0][0]\n",
    "        return frame.values.squeeze()\n",
    "    grouped = frame.groupby(frame.columns[0])\n",
    "    d = {k: recur_dictify(g.iloc[:,1:]) for k,g in grouped}\n",
    "    return d\n",
    "\n",
    "model_name = 'model'\n",
    "\n",
    "d1 = (recur_dictify(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76514b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                with source_1 as (\\n                    select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                    ),\\n                source_2 as (\\n                select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                \\n                ),\\n                \\n                source_3 as (\\n                select * from \"SNOWFLAKE_SAMPLE_DATA\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                \\n                ),\\n                \\n                unioned as (\\n                select * from source_1\\n                \\n                union all\\n                \\n                select * from source_2\\n                \\n                union all\\n                \\n                select * from source_3\\n                \\n                )\\n                select * from unioned\\n                '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41695337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                with source as (\\n                select \\n                *\\n                from \"{{database}}\".\"INFORMATION_SCHEMA\".\"COLUMNS\"\\n                where table_name in \\n                {{ table_names |inclause }}\\n                ),\\n                {% for value in table_names_unqouted  %}\\n                explore_table_row_count_{{ value | sqlsafe }} as (\\n                select \\n                \\'{{ value | sqlsafe }}\\' as table_name,\\n                count(*) as row_count\\n                from \"{{database}}\".\"{{schema_id}}\".\"{{ value | sqlsafe }}\"\\n                group by 1\\n                ),\\n                {% endfor %}\\n                merge_counts as (\\n                {% for value in table_names_unqouted  %}\\n                select * from explore_table_row_count_{{ value | sqlsafe }}\\n                {% if not loop.last %}union all{% endif %}\\n                {% endfor %}\\n                ),\\n                pks as (\\n                    select \\n                    table_name as pk_table_name,\\n                    column_name as pk_column_name,\\n                    trim(column_name, \\'_pk\\') as pk_sk\\n                    from source\\n                    where column_name like \\'%%pk%%\\'\\n                ),\\n                fks as (\\n                    select\\n                    table_name as fk_table_name,\\n                    column_name as fk_column_name,\\n                    trim(column_name, \\'_fk\\') as fk_sk\\n                    from source\\n                    where column_name like \\'%%fk%%\\'\\n                )\\n                select \\n                {{ table_names [0] }} as parent_table_name,\\n                pk_table_name,\\n                pk_column_name,\\n                fk_table_name,\\n                fk_column_name,\\n                merge_counts_pk.row_count as pk_row_count,\\n                merge_counts_fk.row_count as fk_row_count,\\n                merge_counts_parent.row_count as parent_row_count,\\n                case when merge_counts_pk.row_count > merge_counts_fk.row_count\\n                        then \\'many_to_one\\'   \\n                    when merge_counts_pk.row_count < merge_counts_fk.row_count\\n                        then \\'one_to_many\\'\\n                    when merge_counts_pk.row_count = merge_counts_fk.row_count\\n                        then \\'one_to_one\\'\\n                end as true_relationship,\\n                case when merge_counts_pk.row_count < merge_counts_parent.row_count\\n                    and merge_counts_fk.row_count < merge_counts_parent.row_count\\n                    or  merge_counts_pk.row_count != merge_counts_parent.row_count\\n                    and  merge_counts_fk.row_count != merge_counts_parent.row_count\\n                        then \\'many_to_one\\'\\n                    when merge_counts_pk.row_count > merge_counts_parent.row_count\\n                        then \\'one_to_many\\'\\n                    when merge_counts_fk.row_count > merge_counts_parent.row_count\\n                        then \\'one_to_many\\'\\n                    when merge_counts_pk.row_count = merge_counts_parent.row_count\\n                    or merge_counts_fk.row_count = merge_counts_parent.row_count\\n                        then \\'one_to_one\\'                \\n                        \\n                end as looker_relationship\\n                    \\n                    \\n                \\n                \\n                from pks\\n                inner join fks on pks.pk_sk = fks.fk_sk\\n                left join merge_counts as merge_counts_fk on merge_counts_fk.table_name = fks.fk_table_name\\n                left join merge_counts as merge_counts_pk on merge_counts_pk.table_name = pks.pk_table_name\\n                left join merge_counts as merge_counts_parent on merge_counts_parent.table_name = {{ table_names[0] }}\\n                order by looker_relationship\\n                '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookml_explore_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d37a479",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1340779996.py, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import lkml as looker\n",
    "from pprint import pprint\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "from contextlib import redirect_stdout\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "from droughty import config\n",
    "\n",
    "import git\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "credentials = config.service_account\n",
    "\n",
    "warehouse_name = config.warehouse_name\n",
    "lookml_project = config.project_name\n",
    "\n",
    "sql = dbml_reference_dict\n",
    "dimensional_inference_status = dimensional_inference\n",
    "\n",
    "if dimensional_inference_status == 'enabled':\n",
    "\n",
    "    if warehouse_name == 'big_query':\n",
    "\n",
    "        sql = warehouse_target.dbml_reference_dict\n",
    "\n",
    "        # Run a Standard SQL query with the project set explicitly\n",
    "        project_id = lookml_project\n",
    "        df = pandas.read_gbq(sql, dialect='standard', project_id=lookml_project, credentials=credentials)\n",
    "\n",
    "        df['description'] = df['description'].fillna('not available')\n",
    "\n",
    "        df2 = df[['table_name','column_name','data_type','description','pk_table_name','pk_column_name']]\n",
    "\n",
    "        df2['data_type'] = df2['data_type'].str.replace('TIMESTAMP','timestamp')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('DATE','date')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('INT64','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('FLOAT64','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('NUMERIC','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('STRING','varchar')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('BOOL','boolean')\n",
    "        \n",
    "        df3 = {n: grp.loc[n].to_dict('index')\n",
    "\n",
    "        for n, grp in df2.set_index(['table_name', 'column_name','data_type','description','pk_table_name','pk_column_name']).groupby(level='table_name')}\n",
    "\n",
    "        d1 = df3\n",
    "\n",
    "\n",
    "    elif warehouse_name == 'snowflake': \n",
    "\n",
    "        url = URL(\n",
    "\n",
    "            account = config.snowflake_account,\n",
    "            user =  config.snowflake_user,\n",
    "            schema =  config.snowflake_schema,\n",
    "            database =  config.snowflake_database,\n",
    "            password =  config.snowflake_password,\n",
    "            warehouse= config.snowflake_warehouse,\n",
    "            role =  config.snowflake_role\n",
    "\n",
    "        )\n",
    "\n",
    "        engine = create_engine(url)\n",
    "\n",
    "        connection = engine.connect()\n",
    "\n",
    "        query = sql\n",
    "\n",
    "        df = pd.read_sql(query, connection)\n",
    "\n",
    "        df['description'] = df['comment'].fillna('not available')\n",
    "\n",
    "        df2 = df[['table_name','column_name','data_type','description','pk_table_name','pk_column_name']]\n",
    "\n",
    "        df2['data_type'] = df2['data_type'].str.replace('TIMESTAMP','timestamp')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('DATE','date')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('INT64','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('FLOAT64','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('NUMERIC','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('NUMBER','numeric')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('TEXT','varchar')\n",
    "        df2['data_type'] = df2['data_type'].str.replace('BOOL','boolean')\n",
    "\n",
    "        connection.close()\n",
    "        engine.dispose()\n",
    "\n",
    "\n",
    "        df3 = {n: grp.loc[n].to_dict('index')\n",
    "\n",
    "        ##for n, grp in df2.set_index(['table_name', 'column_name','data_type','description','pk_table_name','pk_column_name']).groupby(level='table_name')}\n",
    "\n",
    "        ##d1 = df3\n",
    "    \n",
    "else:\n",
    "\n",
    "    d1 = (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59423f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensional_inference_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539d32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
